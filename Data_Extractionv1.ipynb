{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCMS Data Processing\n",
    "* Data extraction from mdb's to excel workbook.\n",
    "* Extraction of GPS table from mdb's to excel workbook.\n",
    "* Extraction of Texture table from mdb's into excel workbook.\n",
    "* Extraction of Rut table from mdb's into excel workbook.\n",
    "* Extraction of Rough table from mdb's into excel workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Excel files successfully!!\n"
     ]
    }
   ],
   "source": [
    "# importing packages\n",
    "import pyodbc\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "mdb_directory = r\"D:\\_1.Project\\AACM\\Pavement\\Data\\MDB_Processed\" # Define the directory containing MDB files\n",
    "\n",
    "# Define the paths to the Excel files\n",
    "o_gps = r\"D:\\_1.Project\\AACM\\Pavement\\Excel Workbook\\Mdb_data_Workbook\\E_GPS.xlsx\"\n",
    "o_rut = r\"D:\\_1.Project\\AACM\\Pavement\\Excel Workbook\\Mdb_data_WorkbookE_Rut.xlsx\"\n",
    "o_rough = r\"D:\\_1.Project\\AACM\\Pavement\\Excel Workbook\\Mdb_data_Workbook\\E_Rough.xlsx\"\n",
    "o_text = r\"D:\\_1.Project\\AACM\\Pavement\\Excel Workbook\\Mdb_data_Workbook\\E_Text.xlsx\"\n",
    "\n",
    "\n",
    "def read_tables_by_prefix(mdb_file, table_prefix, survey_id): # Define the function to read tables in MDB\n",
    "    conn_str = f\"Driver={{Microsoft Access Driver (*.mdb, *.accdb)}};Dbq={mdb_file};\"\n",
    "    connection = pyodbc.connect(conn_str)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    tables = []\n",
    "    for table_info in cursor.tables(tableType='TABLE'):\n",
    "        table_name = table_info.table_name\n",
    "        if table_name.startswith(table_prefix):\n",
    "            tables.append(table_name)\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    for table in tables:\n",
    "        query = f\"SELECT * FROM [{table}]\"\n",
    "        table_data = pd.read_sql(query, connection)\n",
    "        table_data['survey_id_1'] = survey_id  # Add a new column for Survey_ID and populate with survey_id\n",
    "        data = pd.concat([data, table_data], ignore_index=True)\n",
    "\n",
    "    connection.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_mdb(x): # Define the function to read MDB files\n",
    "    mdb_files = []\n",
    "    for root, dirs, files in os.walk(x):\n",
    "        for file in files:\n",
    "            if file.endswith(\".mdb\"):\n",
    "                mdb_files.append(os.path.join(root, file))\n",
    "    return mdb_files\n",
    "\n",
    "\n",
    "mdb_files = read_mdb(mdb_directory)  # Call the function to read MDB files\n",
    "\n",
    "# Create empty dataframes to store data\n",
    "GPS = pd.DataFrame()\n",
    "Rut = pd.DataFrame()\n",
    "Rough = pd.DataFrame()\n",
    "Texture = pd.DataFrame()\n",
    "\n",
    "\n",
    "for mdb_file in mdb_files:  # Loop through each MDB file and extract data\n",
    "    # Extract data for each table type\n",
    "    gps = read_tables_by_prefix(mdb_file, \"GPS_Processed\", os.path.splitext(os.path.basename(mdb_file))[0])\n",
    "    rut = read_tables_by_prefix(mdb_file, \"LCMS_Rut_Processed\", os.path.splitext(os.path.basename(mdb_file))[0])\n",
    "    rough = read_tables_by_prefix(mdb_file, \"LCMS_Rough_Processed\", os.path.splitext(os.path.basename(mdb_file))[0])\n",
    "    text = read_tables_by_prefix(mdb_file, \"LCMS_Texture_Processed\", os.path.splitext(os.path.basename(mdb_file))[0])\n",
    "    \n",
    "    # Merge the extracted data with the respective dataframe\n",
    "    GPS = pd.concat([GPS, gps], ignore_index=True)\n",
    "    Rut = pd.concat([Rut, rut], ignore_index=True)\n",
    "    Rough = pd.concat([Rough, rough], ignore_index=True)\n",
    "    Texture = pd.concat([Texture, text], ignore_index=True)\n",
    "\n",
    "# Save each dataframe to Excel\n",
    "GPS.to_excel(o_gps, index=False)\n",
    "Rut.to_excel(o_rut, index=False)\n",
    "Rough.to_excel(o_rough, index=False)\n",
    "Texture.to_excel(o_text, index=False)\n",
    "\n",
    "print(\"Data saved to Excel files successfully!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting excel's into tables\n",
    "* creating table of each excels\n",
    "* join coordinates from gps to each table\n",
    "* creating points from each table\n",
    "* creating gps line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully converted and exported to GPS,IRI,Rough and Texture feature classes!\n"
     ]
    }
   ],
   "source": [
    "#import arcpy package\n",
    "import arcpy,os\n",
    "PCI_schema = {}  #Dictionary to store PCI schema \n",
    "IRI_schema = {}  #Dictionary to store IRI schema\n",
    "pci_path = r\"D:\\_1.Project\\AACM\\Schema_Boundaries\\PAVEMENT SCHEMA\\GDB\\AACM_PAVEMENT_GIS_DATABASE.gdb\\PCI\"\n",
    "iri_path = r\"D:\\_1.Project\\AACM\\Schema_Boundaries\\PAVEMENT SCHEMA\\GDB\\AACM_PAVEMENT_GIS_DATABASE.gdb\\IRI\"\n",
    "\n",
    "fields_pci = arcpy.ListFields(pci_path) #iteration over pci feature template to get fields\n",
    "for field in fields_pci:\n",
    "    if not any(substring in field.name for substring in [\"SHAPE\", \"SHAPE_Length\", \"OBJECTID\"]):\n",
    "        IRI_schema[field.name] = (field.aliasName, field.type, field.length) # appending to dictionary\n",
    "\n",
    "\n",
    "fields_iri = arcpy.ListFields(iri_path)  #iteration over iri feature template to get fields\n",
    "for field in fields_iri:\n",
    "    if not any(substring in field.name for substring in [\"SHAPE\", \"SHAPE_Length\", \"OBJECTID\"]):\n",
    "        PCI_schema[field.name] = (field.aliasName, field.type, field.length) # appending to dictionary\n",
    "                 \n",
    "\n",
    "WB_path = r\"D:\\_1.Project\\AACM\\Pavement\\Excel Workbook\\Mdb_data_Workbook\" # excel workbooks path\n",
    "arcpy.env.workspace = r\"D:\\_1.Project\\AACM\\Pavement\\GDB\\Data_Extraction.gdb\" #output workspace\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(WB_path): #converting workbooks into respecitve tables\n",
    "    for file in files:\n",
    "        excel_file_path = os.path.join(root, file)\n",
    "        table_name = \"T\" + file[1:-5]\n",
    "        table_output_path = os.path.join(arcpy.env.workspace, table_name)\n",
    "        arcpy.conversion.ExcelToTable(excel_file_path, table_output_path)\n",
    "        table_name = arcpy.ValidateTableName(table_name)\n",
    "        arcpy.management.AddField(table_name, \"link_1\", \"TEXT\")\n",
    "        expr = \"!survey_id_1! + '_' + str(!CHAINAGE!)\"\n",
    "        arcpy.management.CalculateField(table_name, \"link_1\", expr, \"PYTHON3\")\n",
    "            \n",
    "            \n",
    "for table in arcpy.ListTables(): #adding coordinates to tables\n",
    "    if table != \"T_GPS\":\n",
    "        arcpy.management.JoinField(table, 'link_1', 'T_GPS', 'link_1', ['LONGITUDE','LATITUDE'])         \n",
    "\n",
    "\n",
    "for table in arcpy.ListTables(): # table to gps point and gps line\n",
    "    crs = arcpy.SpatialReference(4326)\n",
    "    out_features = \"P\"+ table[1:]\n",
    "    arcpy.management.XYTableToPoint(table,out_features, 'LONGITUDE','LATITUDE',\"\",crs)\n",
    "    arcpy.management.PointsToLine(\"P_GPS\",\"L_GPS\",\"survey_id_1\")\n",
    "                \n",
    "for f_name, f_props in PCI_schema.items(): #importing gps line into AACM schema \n",
    "    name = f_name\n",
    "    alias = f_props[0]\n",
    "    data_type = f_props[1]\n",
    "    length = f_props[2]\n",
    "    arcpy.management.AddField(\"L_GPS\", field_name=name, field_alias=alias, field_type=data_type, field_length=length)\n",
    "\n",
    "\n",
    "crs_utm = arcpy.SpatialReference(32640) #reprojecting into utm\n",
    "arcpy.management.Project(\"L_GPS\", \"L_GPS_utm\", crs_utm)\n",
    "arcpy.AlterAliasName(\"L_GPS_utm\",\"L_GPS_utm\")\n",
    "\n",
    "print(\"successfully converted and exported to GPS,IRI,Rough and Texture feature classes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute Data population\n",
    "* From direction is populated\n",
    "* To direction is populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully populated From_Dir,o_Dir fields and Orientation\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import arcpy\n",
    "\n",
    "arcpy.env.workspace = r\"D:\\_1.Project\\AACM\\Pavement\\GDB\\Data_Extraction.gdb\"\n",
    "fc = \"pci_test\"\n",
    "\n",
    "def get_compass_direction(azimuth): # Function to calculate compass direction based on azimuth angle\n",
    "    directions = [\"N\", \"NE\", \"E\", \"SE\", \"S\", \"SW\", \"W\", \"NW\"]\n",
    "    sector_size = 360 / len(directions)\n",
    "    sector_index = round(azimuth / sector_size) % len(directions)\n",
    "    return directions[sector_index]\n",
    "\n",
    "with arcpy.da.UpdateCursor(fc, [\"SHAPE@\", \"TODIR\", \"FROMDIR\"]) as cursor: # Update directions in the feature class\n",
    "    for row in cursor:\n",
    "        line = row[0]\n",
    "        start_point = line.firstPoint\n",
    "        end_point = line.lastPoint\n",
    "        azimuth_start = math.atan2(end_point.X - start_point.X, end_point.Y - start_point.Y)\n",
    "        azimuth_end = math.atan2(start_point.X - end_point.X, start_point.Y - end_point.Y)\n",
    "        azimuth_start_degrees = math.degrees(azimuth_start)\n",
    "        azimuth_end_degrees = math.degrees(azimuth_end)\n",
    "        row[1] = get_compass_direction(azimuth_start_degrees)  # Populate From_Dir\n",
    "        row[2] = get_compass_direction(azimuth_end_degrees)  # Populate To_Dir\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "with arcpy.da.UpdateCursor(fc, [\"TODIR\", \"ORIENT\"]) as cursor: # Update directions in the feature class\n",
    "    for row in cursor: \n",
    "        if row[0] in (\"N\", \"E\", \"NE\",\"NW\"):\n",
    "            row[1] = 5\n",
    "        elif row[0] in (\"S\", \"W\", \"SE\" ,\"SW\"):\n",
    "            row[1] = 6\n",
    "        else:\n",
    "            row[1] = 0\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"Successfully populated From_Dir,o_Dir fields and Orientation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* district no\n",
    "* district english name\n",
    "* district arabic name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suceesfully populated district name and district no's into pci lines!!!\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = r\"D:\\_1.Project\\AACM\\Pavement\\GDB\\Data_Extraction.gdb\"\n",
    "fc = \"pci_test\"\n",
    "district_dict = {}\n",
    "district_bound = r\"D:\\_1.Project\\AACM\\Schema_Boundaries\\SCOPE_WORK\\SCOPE_WORK.gdb\\DISTRICT_BOUND\"\n",
    "arcpy.analysis.SpatialJoin(fc,district_bound,\"fc_join\",\"JOIN_ONE_TO_ONE\",\"KEEP_ALL\")\n",
    "\n",
    "with arcpy.da.SearchCursor(\"fc_join\", [\"TARGET_FID\", \"DISTRICT_NO\", \"DISTRICT_NAME_ENG\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        object_id = row[0]\n",
    "        district_no = row[1]\n",
    "        district_name = row[2]\n",
    "        district_dict[object_id] = (district_no, district_name)\n",
    "\n",
    "# Update the \"DISTRICT\" and \"COMMENTS\" fields based on values in the dictionary\n",
    "with arcpy.da.UpdateCursor(fc, [\"OBJECTID\", \"RIGHTOFWAYWIDTH\",\"DISTRICT\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        object_id = row[0]\n",
    "        if object_id in district_dict:\n",
    "            row[1], row[2] = district_dict[object_id]\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "print(\"suceesfully populated district name and district no's into pci lines!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
