{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of GPS in excel from mdb's\n",
    "* Reading mdbs from floder and convert into excel sheet\n",
    "* Print the the number of mdb present in a floder which converted into excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asifi\\AppData\\Local\\Temp\\ipykernel_24348\\1907247421.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  table_data = pd.read_sql(query, connection)\n",
      "C:\\Users\\asifi\\AppData\\Local\\Temp\\ipykernel_24348\\1907247421.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  table_data = pd.read_sql(query, connection)\n",
      "C:\\Users\\asifi\\AppData\\Local\\Temp\\ipykernel_24348\\1907247421.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  table_data = pd.read_sql(query, connection)\n",
      "C:\\Users\\asifi\\AppData\\Local\\Temp\\ipykernel_24348\\1907247421.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  table_data = pd.read_sql(query, connection)\n",
      "C:\\Users\\asifi\\AppData\\Local\\Temp\\ipykernel_24348\\1907247421.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  table_data = pd.read_sql(query, connection)\n",
      "C:\\Users\\asifi\\AppData\\Local\\Temp\\ipykernel_24348\\1907247421.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  table_data = pd.read_sql(query, connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Successfully completed!!\n"
     ]
    }
   ],
   "source": [
    "import pyodbc,os,pandas as pd\n",
    "\n",
    "mdb_directory = r\"D:\\_2.Programming\\_6.test\\mdb_processed\" # input directory\n",
    "o_gps = r\"D:\\_2.Programming\\_6.test\\Ex_GPS.xlsx\" # output directory\n",
    "\n",
    "#defining function to read mdb's\n",
    "def read_mdb(x):\n",
    "    mdb_files = []\n",
    "    for root, dirs, files in os.walk(x):\n",
    "        for file in files:\n",
    "            if file.endswith(\".mdb\"):\n",
    "                mdb_files.append(os.path.join(root, file))\n",
    "    return mdb_files\n",
    "\n",
    "#defining function to read tables in mdb\n",
    "def read_tables_by_prefix(mdb_file, table_prefix):\n",
    "    conn_str = f\"Driver={{Microsoft Access Driver (*.mdb, *.accdb)}};Dbq={mdb_file};\"\n",
    "    connection = pyodbc.connect(conn_str)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    tables = []\n",
    "    for table_info in cursor.tables(tableType='TABLE'):\n",
    "        table_name = table_info.table_name\n",
    "        if table_name.startswith(table_prefix):\n",
    "            tables.append(table_name)\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    for table in tables:\n",
    "        query = f\"SELECT * FROM [{table}]\"\n",
    "        table_data = pd.read_sql(query, connection)\n",
    "        table_data['Survey_ID_1'] = os.path.splitext(os.path.basename(mdb_file))[0]\n",
    "        data = pd.concat([data, table_data], ignore_index=True)\n",
    "\n",
    "    connection.close()\n",
    "    return data\n",
    "\n",
    "#calling function to read mdb's\n",
    "mdb_files = read_mdb(mdb_directory)\n",
    "\n",
    "#pandas data frame for storing extracted gps and keycode\n",
    "GPS_P = pd.DataFrame()\n",
    "\n",
    "#extracting and merging gps and keycode from mdb's \n",
    "for mdb_file in mdb_files:\n",
    "    gps = read_tables_by_prefix(mdb_file, \"GPS_Processed\")\n",
    "    GPS_P = pd.concat([GPS_P, gps], ignore_index=True)\n",
    "\n",
    "#exporting gps and keycode from pandas data frame\n",
    "GPS_P.to_excel(o_gps, index=False)\n",
    "\n",
    "print(len(mdb_files))\n",
    "print(\"Successfully completed!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating feature classes from excel data\n",
    "* Excel to table \n",
    "* Table to point \n",
    "* Point to line in WGS & UTM\n",
    "* Adding schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_gps = r\"D:\\_2.Programming\\_6.test\\Ex_GPS.xlsx\" # input directory\n",
    "arcpy.env.overwriteOutput = 1\n",
    "arcpy.env.workspace = r\"D:\\_2.Programming\\_6.test\\test.gdb\" # workspace\n",
    "arcpy.ExcelToTable_conversion(in_gps, \"T_GPS\", \"Sheet1\")\n",
    "arcpy.management.XYTableToPoint(\"T_GPS\",\"P_GPS\",\"LONGITUDE\",\"LATITUDE\",\"\",arcpy.SpatialReference(4326))\n",
    "arcpy.management.PointsToLine(\"P_GPS\", \"L_GPS\", \"Survey_ID_1\") # L_GPS is in WGS-84\n",
    "arcpy.management.AddFields(\"L_GPS\",[[\"STREET_NAME\",\"TEXT\"],[\"STREET_ID\",\"TEXT\"],[\"IP_IP\",\"TEXT\"], [\"DIRECTION\",\"TEXT\"],\n",
    "                                            [\"From_\",\"TEXT\"],[\"To\",\"TEXT\"],[\"Length\",\"DOUBLE\"],[\"SECTION_NO\",\"DOUBLE\"]])\n",
    "utm_crs = arcpy.SpatialReference(32640)\n",
    "arcpy.management.Project(\"L_GPS\",\"L_GPS_utm\",utm_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flip line based on direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.workspace = r'D:\\_2.Programming\\_6.test\\test.gdb'\n",
    "field = 'DIRECTION' # specify field name based on which flip will undergo\n",
    "infc = 'L_GPS_utm' # specify feature class\n",
    "def flip_line_geometry(line): # Define a function to flip line geometry\n",
    "    reversed_coords = [(point.X, point.Y) for point in reversed(line.getPart(0))]\n",
    "    return arcpy.Polyline(arcpy.Array([arcpy.Point(x, y) for x, y in reversed_coords]))\n",
    "with arcpy.da.UpdateCursor(infc, [\"SHAPE@\", field]) as cursor: # Update the geometry of lines that meet the condition\n",
    "    for row in cursor:\n",
    "        direction = row[1]\n",
    "        if direction == \"Dec\":\n",
    "            line_geometry = row[0]\n",
    "            flipped_line = flip_line_geometry(line_geometry)\n",
    "            row[0] = flipped_line\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "print(\"Successfully completed!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating points from GPS line\n",
    "* points interval is dynamic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import math\n",
    "import os\n",
    "\n",
    "arcpy.env.workspace = r'D:\\_2.Programming\\_6.test\\test.gdb'\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "in_Fc = 'L_GPS_utm'\n",
    "ofc_Points = 'points_100m'\n",
    "interval_distance = 100\n",
    "\n",
    "\n",
    "# Add fields to store the interval number, Unique_ID, and Line_ID\n",
    "arcpy.CreateFeatureclass_management(out_path=os.path.dirname(ofc_Points),out_name=os.path.basename(ofc_Points),geometry_type=\"POINT\",spatial_reference= in_Fc)\n",
    "\n",
    "arcpy.AddFields_management(ofc_Points, [[\"Interval\", \"LONG\"],[\"Chainage\", \"LONG\"],[\"Section_No\", \"LONG\"]])\n",
    "\n",
    "# Start an insert cursor\n",
    "with arcpy.da.InsertCursor(ofc_Points, [\"SHAPE@\", \"Interval\", \"Chainage\", \"Section_No\"]) as cursor:\n",
    "    interval = 0    \n",
    "    with arcpy.da.SearchCursor(in_Fc, [\"SHAPE@\"]) as search_cursor:\n",
    "        for row in search_cursor:\n",
    "            line = row[0]\n",
    "            length = line.length  # Get the length of the line\n",
    "            i = 0\n",
    "            chainage = 0  # Initialize the Unique_ID for the current line\n",
    "            sec_no = 1\n",
    "            while i < length:\n",
    "                point = line.positionAlongLine(i)\n",
    "                cursor.insertRow([point, interval, chainage, sec_no])\n",
    "                interval += 1\n",
    "                chainage += 100\n",
    "                sec_no += 1\n",
    "                i += interval_distance   \n",
    "print (\"sucessfully created points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting pms lines on 100m of sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "\n",
    "arcpy.env.workspace = r'D:\\_2.Programming\\_6.test\\test.gdb'\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "in_Fc = 'L_GPS_utm'\n",
    "in_Point = 'points_100m'\n",
    "out_Fc = 'PMS_Sections'\n",
    "\n",
    "radius = 0.5\n",
    "\n",
    "# Split the line at points using arcpy.SplitLineAtPoint_management\n",
    "arcpy.SplitLineAtPoint_management(in_Fc, in_Point, out_Fc, radius)\n",
    "\n",
    "# Create a dictionary to store the cumulative lengths for each line\n",
    "cumulative_lengths = {}\n",
    "\n",
    "# Use an update cursor to calculate and populate the \"FromValue\" field\n",
    "with arcpy.da.UpdateCursor(out_Fc, [\"SHAPE@\", \"OID@\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        line_geometry = row[0]\n",
    "        oid = row[1]\n",
    "        \n",
    "        # Check if the geometry is multipart\n",
    "        if line_geometry.isMultipart:\n",
    "            # If multipart, iterate over parts and update each part separately\n",
    "            cumulative_length = 0.0\n",
    "            for part in line_geometry:\n",
    "                cumulative_length += part.length\n",
    "        else:\n",
    "            cumulative_length = line_geometry.length\n",
    "        \n",
    "        # Update the cumulative length for this line\n",
    "        cumulative_lengths[oid] = cumulative_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populating attributes\n",
    "* From,To,section_no and length fields are populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "\n",
    "arcpy.env.workspace = r'D:\\_2.Programming\\_6.test\\test.gdb'\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "in_Fc = 'PMS_Sections'\n",
    "in_Points = 'points_100m'\n",
    "\n",
    "# Create a dictionary to store point coordinates and their corresponding Unique_IDs\n",
    "point_dict = {}\n",
    "to_dict = {}\n",
    "\n",
    "with arcpy.da.SearchCursor(in_Points, [\"SHAPE@\", \"Chainage\", \"Section_No\"]) as cursor:\n",
    "    for sc in cursor:\n",
    "        point = sc[0].firstPoint  # Get the first point of the geometry\n",
    "        chainage = sc[1]\n",
    "        section_no = sc[2]\n",
    "        point_coords = (point.X, point.Y)  # Convert point to a tuple of coordinates\n",
    "        point_dict[point_coords] = chainage\n",
    "        to_dict[point_coords] = section_no\n",
    "\n",
    "# Update the \"FROM\", \"TO\", and \"LENGTH\" fields in PMS_Sections\n",
    "with arcpy.da.UpdateCursor(in_Fc, [\"SHAPE@\", \"From_\", \"SECTION_NO\",\"To\", \"Length\"]) as up_cursor:\n",
    "    for up in up_cursor:\n",
    "        line_geometry = up[0]\n",
    "        first_point = (line_geometry.firstPoint.X, line_geometry.firstPoint.Y)  # Convert to tuple\n",
    "        \n",
    "        # Check if the exact coordinate match exists\n",
    "        if first_point in point_dict:\n",
    "            up[1] = point_dict[first_point]\n",
    "            up[3] = up[1] + round(up[0].length,0)\n",
    "            up[4] = round(up[0].length,0)\n",
    "            up_cursor.updateRow(up)\n",
    "        else:\n",
    "            # If no exact match, find the nearest point\n",
    "            nearest_point = min(point_dict.keys(), key=lambda p: arcpy.PointGeometry(arcpy.Point(*p)).distanceTo(line_geometry.firstPoint))\n",
    "            up[1] = point_dict[nearest_point]\n",
    "            up_cursor.updateRow(up)\n",
    "\n",
    "        # Similar logic for the \"TO\" field\n",
    "        if first_point in to_dict:\n",
    "            up[2] = to_dict[first_point]\n",
    "            up_cursor.updateRow(up)\n",
    "        else:\n",
    "            # If no exact match, find the nearest point\n",
    "            nearest_point = min(to_dict.keys(), key=lambda p: arcpy.PointGeometry(arcpy.Point(*p)).distanceTo(line_geometry.firstPoint))\n",
    "            up[2] = to_dict[nearest_point]\n",
    "            up_cursor.updateRow(up)\n",
    "\n",
    "print(\"Successfully populated FROM, TO, and LENGTH fields.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
